---
title: "Predictive Models"
date: 2024-09-20T10:00:00-04:00
draft: false
tags: ["AI Safety", "Research", "Ethics"]
---
[Link to sign up](https://www.meetup.com/toronto-ai-aligners/events/303101704/?eventOrigin=group_upcoming_events)

Getting here: Enter the lobby at 100 University Ave (right next to St Andrew subway station), and message Giles Edkins on the meetup app or call him on 647-823-4865 to be let up to room 6H.

Rubi Hudson will introduce us to Predictive Models, how they might help address existential risks from AI, as well as some of the dangers and caveats of this approach.

Today's (pretrained) large language models can be thought of as systems that predict text. With systems such as GPT-4o we are already seeing this augmented with predictive capabilities for other modalities such as audio and video. And in theory it can be extended to predict anything that can be measured.

What could we do with a powerful predictive model? One thing - which Rubi sees as a risk which frontier labs should be careful to avoid - is to build a scaffold around them, turning the predictive model into a consequentialist agent. But we could also use them in ways that reduce risk: predicting solutions to alignment, or predicting the effects of policies and governance structures.

Come and learn more about this approach to safety!

We welcome a variety of backgrounds, opinions and experience levels.
